# Customer Churn Prediction (Telco) — ML + API

ML-сервис для прогнозирования вероятности оттока клиента (churn probability) и использования результата в retention-кампаниях.

---

## 1) Бизнес-контекст

**Задача:** снизить отток клиентов за счёт таргетированных удерживающих действий (скидка, звонок, апгрейд тарифа, улучшение сервиса).

**Что предсказываем:** `P(churn=1 | customer_features)` — вероятность ухода клиента.

**Как это применять:**
- ранжирование клиентов по риску (Top-K) для работы колл-центра;
- удерживающие офферы (discount/benefit) только тем, у кого ожидаемая выгода положительна;
- контроль качества сегментов (месяц-к-месяцу, новые клиенты, отсутствие автоплатежа и т.д.).

---

## 2) Метрики и связь с деньгами

### ML-метрики (оценка качества ранжирования)
- ROC-AUC (основная)
- PR-AUC (важно при дисбалансе)
- Recall@K / Precision@K (если у нас фиксирован ресурс обработки клиентов)

### Бизнес-метрики (для решения “кого трогать”)
Для каждого клиента оцениваем **ожидаемую выгоду** удержания:

**Expected Value (упрощённо):**
- `EV = P(churn) * (LTV_saved) - Cost_action`

Где:
- `LTV_saved` — сколько денег мы сохраняем, если удержали клиента
- `Cost_action` — стоимость удерживающего действия (скидка/звонок/бонус)

### Выбор порога (threshold)
В коде используется порог `THRESHOLD=0.5` по умолчанию, но **в проде порог должен определяться бизнесом** (ценой FP/FN и capacity команды). Порог хранится в конфиге и может быть изменён отдельно от модели.

---

## 3) Данные

Источник: **Telco Customer Churn** (Kaggle).

Ожидаемые признаки: демография, контракт, услуги, платежи, tenure, charges.  
Таргет: `Churn` приводится к бинарному виду (yes/no → 1/0).

---

## 4) Модель и пайплайн

### Что внутри
- Предобработка + выравнивание колонок для стабильного инференса (если API прислал не все поля)
- Очистка/импьютинг
- Feature Engineering (бизнес-фичи: tenure buckets, num_services, high_charges, auto_pay и др.)
- One-Hot Encoding категорий
- Модель: CatBoost (sklearn-compatible wrapper)

См. реализацию пайплайна: `src/pipeline.py`.

---

## 5) Структура проекта

- `src/train_pipeline.py` — обучение, holdout-оценка, сохранение `models/churn_pipeline.pkl`
- `src/config.py` — пути, параметры сплита, порог
- `app/main.py` — FastAPI сервис `/health`, `/predict`
- `app/schemas.py` — Pydantic схемы запроса/ответа
- `tests/test_api.py` — тесты API (pipeline мокается)

---

## 6) Запуск (локально)

### Установка
```bash
pip install -r requirements.txt
```
 
### Обучение модели
```bash
python -m src.train_pipeline
```

### Запуск API
```bash
uvicorn app.main:app --host 0.0.0.0 --port 8080
```

---

## Версионирование моделей и артефактов

Модель сохраняется как **версионированный артефакт**:

- `models/<MODEL_VERSION>/churn_pipeline.pkl`
- `models/<MODEL_VERSION>/manifest.json`

`manifest.json` содержит:
- sha256 сырого датасета
- sha256 кода (детерминированный отпечаток файлов)
- sha256 артефакта модели
- версии ключевых пакетов и параметры обучения

### Как выбрать версию в API

По умолчанию API грузит `models/latest` (или `models/latest.txt` как портативный указатель).

Чтобы зафиксировать конкретную версию:

```bash
export MODEL_VERSION=20260202_120000Z_ab12cd
uvicorn app.main:app --host 0.0.0.0 --port 8080
```

Проверка:
- `GET /health` возвращает `model_version`, `data_sha256`, `code_sha256`.